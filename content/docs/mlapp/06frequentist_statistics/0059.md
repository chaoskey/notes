---
title: "习题"
date: 2019-07-17T20:20:35+08:00
draft: true
categories: ["机器学习"]
tags: ["习题"]
---


[**返回本章目录**]({{< relref "/docs/mlapp/06frequentist_statistics" >}})

**练习6.1** LOOCV的最坏情况

（来源：Witten05，p152。）。 假设我们有一个完全随机标记的数据集（即，特征$\boldsymbol{x}$没有告诉我们关于类标签$y$的任何内容），其中类1有$N_1$个样本，类2有$N_2$个样本，并且$N_1 = N_2$。 任何方法可以实现的最佳错分率是多少？ 使用LOOCV对同一方法的估计的错分类率是多少？

<!--more-->

**练习6.2** 高斯均值的James Stein估计器

考虑2阶段模型$Y_i |\theta_i \sim \mathcal{N}(\theta_i,\sigma^2)$和$\theta_i|\mu \sim \mathcal{N}(m_0，\tau_0^2)$。 假设$\sigma^2= 500$是已知的，我们观察了以下6个数据点，$i = 1:6$：

1505, 1528, 1564, 1498, 1600, 1470

* a. 求出$m_0$和$\tau_0^2$的ML-II估计。
* b. 对于$i = 1$, 求出后验估计$\mathbb{E} [\theta_i | y_i, m_0, \tau_0]$和${\rm var} [\theta_i | y_i, m_0, \tau_0]$。（其他项$i = 2:6$，也类似地计算。）
* c. 对于$i = 1$，给出$p(\theta_i | y_i, m_0, \tau_0)$的95％可信区间。你确信这个区间（假设高斯假设是合理的）吗？ 即它可能太大或太小，或者恰到好处？
* d. 如果$\sigma^2$小得多（比如说$\sigma^2= 1$），你对你的估计会有什么期望？ 您不需要计算数字答案; 只是简单地定性解释一下会发生什么，以及为什么。

**练习6.3** $\hat{\sigma}_{\rm MLE}^2$是有偏的

证明$\hat{\sigma}_{\rm MLE}^2= \frac{1} {N} \sum_{n = 1}^N{(x_n-\hat{\mu})^2}$ 是$\sigma^2$的有偏估计器，即证明

$$
\mathbb{E}_{X_1,\dots,X_n \sim \mathcal{N}(\mu,\sigma)}[\hat{\sigma}^2(X_1,\dots,X_n)]\ne \sigma^2
$$

提示：请注意，$X_1,\dots,X_N$是独立的，并且使用独立随机变量乘积的期望是期望的乘积这一事实。

**练习6.4** 当$\mu$已知时, 估计$\sigma^2$

假设我们采样$x_1,\dots,x_N \sim \mathcal{N}(\mu, \sigma^2)$ ，其中$\mu$ 是已知常数。 在这种情况下，为$\sigma^2$导出MLE的表达式。 它是无偏的吗？

[**返回本章目录**]({{< relref "/docs/mlapp/06frequentist_statistics" >}})

