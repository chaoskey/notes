---
title: "习题"
date: 2019-07-11T20:20:35+08:00
draft: true
categories: ["机器学习"]
tags: ["习题"]
---


[**返回本章目录**]({{< relref "/docs/mlapp/05bayesian_statistics" >}})

**习题5.1** 证明共轭先验的混合确实是共轭的

推导等式5.69.

<!--more-->

**习题5.2** 分类概率的最佳阈值

考虑我们已经学到了条件概率分布$P(y|\boldsymbol{x})$的情况。 假设只有两个类，并且令$p_0 = P(Y = 0 | \boldsymbol{x})$并且$p_1 = P(Y = 1 | \boldsymbol{x})$。 考虑下面的损失矩阵：

| 预测标签$\hat{y}$  $\Downarrow$      真值标签$y$  $\Rightarrow$ | 0 | 1 |
| :---: | :---: | :---: |
| 0 | 0 | $\lambda_{01}$ |
| 1 | $\lambda_{10}$ | 0 |

* a. 最小化预期损失的决策$\hat{y}$等价于设定概率阈值$\theta$并且如果$p_1 <\theta$则预测$\hat{y} = 0$并且如果$p_1\le \theta$则预测$\hat{y} = 1$。 那么$\theta$作为$\lambda_{01}$和$\lambda_{10}$的函数是什么？（展现你的工作。）
* b. 展现阈值为0.1的损失矩阵。 （展现你的工作。）

**习题5.3** 分类中的拒绝选项

（来源：（Duda et al.2001，Q2.13）。）

在许多分类问题中，可以选择将$\boldsymbol{x}$分配给$j$类，或者如果你太不确定，可以选择**拒绝选项**。 如果拒绝的成本低于错误对对象进行分类的成本，则可能是最佳操作。 设$\alpha_i$表示你选择动作$i, i = 1:C+1$，其中$C$是类的数量，$C + 1$是拒绝动作。 设$Y = j$是真的（但未知）的**自然状态**。 确定损失函数如下

$$
\lambda(\alpha_i|Y=j)=\left\{
\begin{aligned}
0\quad & if \quad i=j \ and \ i,j \in \{1,\dots,C\} \\
\lambda_r \quad & if \quad i=C+1 \\
\lambda_s \quad & otherwise
\end{aligned}
\right. \tag{5.122}
$$

换句话说，如果您正确分类，则会导致0损失，如果您选择拒绝选项，则会产生$\lambda_r$损失（成本），如果您发生替换错误（错误分类），则会导致$\lambda_s$损失（成本）。

权衡，人们需要使用某种“货币”来比较不同的行动方式。保险公司一直这样做。斯坦福大学决策理论家罗斯·沙克特（Ross Schachter）喜欢讲述一个学校董事会的故事，他拒绝了一项关于从学校清除石棉的研究，因为它进行了一项**成本效益分析**，被认为是“不人道”的，因为他们为孩子的健康付出了美元价值; 拒绝报告的结果是石棉没有被移除，这肯定更“不人道”。在医学领域，人们通常用**QALY**或质量调整的生命年来衡量效用，而不是美元，但这是相同的想法。当然，即使您没有明确说明您对不同人的生活有多重视，您的行为也会揭示您的隐含价值/偏好，然后可以将这些偏好转换为实际值，例如美元或QALY。从行为推断效用函数称为**逆强化学习**\(**inverse reinforcement learning**\)。

* a. 如果$p(Y=j|\boldsymbol{x})\ge p(Y = k | \boldsymbol{x}), \forall k$\(即, $j$是最可能的类\)，并且$p(Y=j|\boldsymbol{x}) \ge 1 - \frac{\lambda_r}{\lambda_s}$，于是可确定$Y=j$。 请你展示如果可以这样则可获得最小风险; 否则我们决定拒绝。
* b. 定性地描述当从$\frac{\lambda_r}{\lambda_s}$从0增加到1时发生的情况（即，拒绝的相对成本增加）。

**习题5.4** 更多拒绝选项

在许多应用程序中，分类器被允许“拒绝”测试示例，而不是将其分类到其中一个类中。 例如，考虑一个错误分类的成本是10美元的情况，但是人工手动做出决定的成本仅为3美元。 我们可以将其表示为以下损失矩阵：

| $\hat{y} \Downarrow$      $y \Rightarrow$ | 0 | 1 |
| :---: | :---: | :---: |
| 0 | 0 | 10 |
| 1 | 10 | 0 |
| 拒绝 | 3 | 3 |

* a. 假设$P((y = 1|\boldsymbol{x})$ 预计是0.2。 那么最小期望损失的决策是那个?
* b. 现在假设$P((y = 1|\boldsymbol{x})=0.4$ 。那么现在最小期望损失的决策是那个?
* c. 一般来说，对于这个同样的损失矩阵，但对于任何后验分布而言，都会有两个阈值$\theta_0$和$\theta_1$，这样最优决策是：如果$p_1 <\theta_0$，则预测为0；如果$\theta_0 \le p_1 \le \theta_1$，则拒绝；如果$p_1 \ge \theta_1$，则预测为1（其中, $p_1 = p(y = 1 | \boldsymbol{x})$）。 这些阈值应该是多少？

**习题5.5** 报童问题

考虑决策理论/经济学中的以下经典问题。 假设您正在尝试确定某些产品（例如报纸）的购买量Q以最大化您的利润。 最佳金额将取决于您认为您的产品需求量D，以及您的成本C和销售价格P。假设D未知但具有pdf $f(\mathcal{D})$和cdf $F(\mathcal{D})$。 我们可以通过考虑两种情况来评估预期的利润：如果$D> Q$，那么我们可卖掉所有的Q，并且得到利润$\pi=(P - C) Q$; 但如果$D \lt Q$，我们只卖出D，获得利润$(P - C) D$，但在未售出部分上浪费了$C(Q-D)$。 因此，如果我们购买量Q，预期的利润是

$$
\mathbb{E} \ \pi(Q) = \int_Q^\infty{(P-C)Qf(D)dD} + \int_0^Q{(P-C)Df(D)dD}-\int_0^Q{C(Q-D)f(D)dD} \tag{5.123}
$$

简化此表达式，然后利用Q的导数来获得最佳数量Q \*（最大化预期利润）满足

$$
F(Q^*)=\dfrac{P-C}{P} \tag{5.124}
$$

**习题5.6** 贝叶斯因子和ROC曲线

设$B = p(D | H_1)/ p(D | H_0)$是有利于模型1的贝叶斯因子。假设我们绘制两条ROC曲线，一条通过阈值B计算，另一条通过阈值处理$p(H_1 | D)$计算 。 他们会是相同还是不同？ 请解释为什么？

**习题5.7** 贝叶斯模型平均有助于预测准确性

设$\Delta$是我们想要预测的量，这$\mathcal{D}$为观测数据，$\mathcal{M}$为有限的模型集。 假设为我们的动作是提供概率性预测$p(.)$，并且损失函数是$L(\Delta,p(.))= - \log p(\Delta)$。 我们可以执行贝叶斯模型平均并使用下式进行预测

$$
p^{\rm BMA}(\Delta)=\sum_{m\in\mathcal{M}}{p(\Delta|m,\mathcal{D})p(m|\mathcal{D})} \tag{5.125}
$$

或者, 我们能使用任何一个单模型进行预测\(插入近似\)

$$
p^m(\Delta)=p(\Delta|m,\mathcal{D})  \tag{5.126}
$$

证明，对于所有模型$m\in \mathcal{M}$，使用BMA的后验预期损失较低，即

$$
\mathbb{E}\left[L(\Delta,p^{\rm BMA})\right] \le \mathbb{E}\left[L(\Delta,p^m)\right]  \tag{5.127}
$$

对$\Delta$的期望是相对于

$$
p(\Delta|\mathcal{D})=\sum_{m\in \mathcal{M}}{p(\Delta|m,\mathcal{D})p(m|\mathcal{D})} \tag{5.128}
$$

提示：使用非负的KL散度。

**习题5.8** 用于二维离散分布的MLE和模型选择

\(来源: Jaakkola.\)

设$x\in \{0,1\}$表示抛硬币的结果（反面$x = 0$，正面$x = 1$）。 硬币可能存在偏差，因此头部的概率为$\theta_1$。假设其他人观察硬币并向您报告结果$y$。 但是这个人不可靠，只能用概率$\theta_2$正确地报告结果; 即$p(y | x,\theta_2)$由下式给出

|  | $y=0$ | $y=1$ |
| :---: | :---: | :---: |
| $x=0$ | $\theta_2$ | $1-\theta_2$ |
| $x=1$ | $1-\theta_2$ | $\theta_2$ |

假设$\theta_2$与$x$和$\theta_1$无关。

* a. 以2×2表格的方式写下联合概率分布$p(x，y |\boldsymbol{\theta})$，其中$\boldsymbol{\theta}=(\theta_1,\theta_2)$。
* b. 假设有以下数据集：$\boldsymbol{x} =(1,1,0,1,1,0,0), \boldsymbol{y} =(1,0,0,0,1,0,1)$。 $\theta_1$和$\theta_2$的MLE是多少？ 证明你的答案。 提示：请注意似然函数因子，

$$
p(x,y | \boldsymbol{\theta})=p(y|x,\theta_2)p(x|\theta_1)   \tag{5.129}
$$

​ $p(\mathcal{D} | \hat{\boldsymbol{\theta}}, M_2)$是什么？其中$M_2$表示一个2参数模型。 （如果您愿意，可以以分数形式留下您的答案。）

* c. 现在考虑具有4个参数的模型，$\boldsymbol{\theta}=(\theta_{00},\theta_{01},\theta_{10},\theta_{11})$，表示$p(x，y |\boldsymbol{\theta})=θ_{xy}$。 （这些参数中只有3个是可以自由变化的，因为它们总和必须为1。） $\boldsymbol{\theta}$的MLE是多少？ $p(\mathcal{D} |\boldsymbol{\theta},M_4)$是什么？ 其中$M_4$表示一个4参数模型。
* d. 假设我们不确定哪种模型是正确的。 我们计算2参数模型和4参数模型的**留一交叉验证**对数似然如下：

$$
L(m)=\sum_{i=1}^n{\log p (x_i,y_i|m,\hat{\theta}(\mathcal{D}_{-i}))}   \tag{5.130}
$$

​ 并且$\hat{\theta}(\mathcal{D}_{-i})$表示在排除第$i$行的$\mathcal{D}$上计算的MLE。 CV选择哪模型？为什么？ 提示：注意当您一次省略一个训练样本时，计数表如何变化。

* e. 回想一下CV的替代方案是使用BIC得分，定义为

$$
{\rm BIC}(M,\mathcal{D})\overset{\Delta}{=} \log p(\mathcal{D}|\hat{\boldsymbol{\theta}}_{\rm MLE})-\dfrac{{\rm dof}(M)}{2} \log N   \tag{5.131}
$$

​ 其中${\rm dof}(M)$是模型中自由参数的数量，计算两个模型的BIC分数（使用基于e的$\log$）。 BIC更喜欢哪种模型？

**习题5.9** 后验中位数是$L_1$损失下的最佳估计值

证明后验中位数是$L_1$损失下的最优估计。

**习题5.10** FP和FN权衡的决策规则

如果$L_{\rm FN} = c L_{\rm FP}$，证明我们应该选择$\hat{y} = 1$当且仅当$p(y = 1 | \boldsymbol{x})/ p(y = 0 | \boldsymbol{x})>\tau$，其中$\tau= c /(1+c)$

[**返回本章目录**]({{< relref "/docs/mlapp/05bayesian_statistics" >}})
