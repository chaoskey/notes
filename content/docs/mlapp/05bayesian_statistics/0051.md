---
title: "5.7 贝叶斯决策理论"
date: 2019-07-10T20:20:35+08:00
draft: true
categories: ["机器学习"]
tags: ["理性行为", "损失函数", "贝叶斯", "估计量", "监督学习", "效用"]
---


[**返回本章目录**]({{< relref "/docs/mlapp/05bayesian_statistics" >}})

我们已经看到概率论如何用来表示和更新我们对世界状况的信念\( beliefs\)。 然而，最终我们的目标是将我们的信念转化为行动。 在本节中，我们将讨论实现此目的的最佳方法。

<!--more-->

我们可以将任何给定的统计决策问题形式化为对抗自然的游戏（与针对其他战略玩家的游戏相反，这是游戏理论的主题，参见例如（Shoham和Leyton-Brown 2009）的细节）。 在这个游戏中，大自然选择一个状态或参数或标签$y\in \mathcal{Y}$，这对我们是未知的，然后生成一个观察，$x\in \mathcal{X}$，这是我们可看到的。 然后我们必须做出决策，也就是说，我们必须从某个**动作空间**\(**action space**\)$\mathcal{A}$中选择一个动作。 最后，我们会产生一些**损失**$L(y,a)$，它衡量我们的行为与自然隐藏状态$y$的相容程度。 例如，我们可能会使用错误分类损失$L(y,a)= \mathbb{I}(y\ne a)$或平方损失$L(y,a)=(y-a)^2$。我们将在下面看到其他一些例子。

我们的目标是设计一个**决策程序**或**策略**$\delta:\mathcal{X} \to \mathcal{A}$，它规定了每种可能输入的最佳行动。 这个最佳，意思是最小化预期损失的行为：

$$
\delta(\boldsymbol{x}) = \underset{a \in \mathcal{A}}{\rm argmin} \ \mathbb{E}[L(y,a)] \tag{5.96}
$$

在经济学中，谈论**效用函数**更为常见; 这只是负损失，$U(y,a)= - L(y,a)$。 因此，上述规则成为

$$
\delta(\boldsymbol{x}) = \underset{a \in \mathcal{A}}{\rm argmax} \ \mathbb{E}[U(y,a)] \tag{5.97}
$$

这被称为**最大期望效用原则**，是我们**理性行为**的本质。

请注意，我们对“预期”的含义有两种不同的解释。 在我们下面讨论的贝叶斯版本中，我们指的是给定我们目前所见数据的$y$的预期值。 在我们在6.3节讨论的频率论版本中，我们指的是我们期望在未来看到的$y$和$\boldsymbol{x}$的期望值。

在贝叶斯决策理论方法中，已经观察到$\boldsymbol{x}$下的最优作用被定义为最小化**后验预期损失**的动作$a$：

$$
\rho(a|\boldsymbol{x}) \overset{\Delta}{=} \mathbb{E}_{p(y|\boldsymbol{x})} [L(y,a)] = \sum_y{L(y,a)p(y|\boldsymbol{x})} \tag{5.98}
$$

（如果$y$是连续的（例如，当我们想要估计参数向量时），我们应该用积分替换和。）因此**贝叶斯估计量**，也称为**贝叶斯决策规则**，由下式给出：

$$
\delta(\boldsymbol{x}) = \underset{a\in \mathcal{A}}{\rm argmin} \ \rho(a | \boldsymbol{x}) \tag{5.99}
$$

## 5.7.1 贝叶斯估计量的常用损失函数

在本节中，我们将展示在机器学习中如何用最常见的损失函数来构建贝叶斯估计器。

### 5.7.1.1 MAP估计最小化0-1损失

**0-1损失**被定义为:

$$
L(y,a) = \mathbb{I}(y \ne a) = \left\{
\begin{aligned}
0 \quad & if\quad a=y \\
1 \quad & if\quad a \ne y
\end{aligned}
\right.  \tag{5.100}
$$

这通常用于分类问题，其中$y$是真值类标签，$a = \hat{y}$是估计值。

例如，在两个类的情况下，我们可以编写如下的损失矩阵下所示：

|  | $\hat{y}=1$ | $\hat{y}=0$ |
| :---: | :---: | :---: |
| $y=1$ | 0 | 1 |
| $y=0$ | 1 | 0 |

（在第5.7.2节中，我们推广了这个损失函数，因此它会对不对角线上的两种误差进行不同的处理。）

后验预期损失是

$$
\rho(a | \boldsymbol{x})=p(a \ne y | \boldsymbol{x}) = 1 - p(y|\boldsymbol{x}) \tag{5.101}
$$

因此，使最小化预期损失的动作是后验众数\(mode\)或MAP估计

$$
y^{*}(\boldsymbol{x})= \underset{y \in \mathcal{Y}}{\rm arg max} \ p(y | \boldsymbol{x}) \tag{5.102}
$$

### 5.7.1.2 拒绝选项

在$p(y | \boldsymbol{x})$非常不确定的分类问题中，我们可能更愿意选择**拒绝动作**，其中我们拒绝将案例分类为任何指定的类，而是说“不知道”。 这种模糊的情况可以由例如人类专家处理。 有关说明，请参见图5.13。 这在医学和金融等**风险规避**领域很有用。

我们可以将**拒绝选项**形式化如下。 令选择$a = C + 1$对应于选择拒绝动作，并选择$a\in \{1,\dots,C\}$对应于选择其中一个类。 假设我们定义损失函数如下

$$
L(y=j,a=i)=\left\{
\begin{aligned}
0 \quad & if \quad i=j \ and \ i,j \in  \{1,\dots,C \} \\
\lambda_r \quad & if \quad i=C+1 \\
\lambda_s \quad & otherwise
 \end{aligned}
\right.  \tag{5.103}
$$

其中$\lambda_r$是拒绝动作的代价，$\lambda_s$是**替换错误**\(**substitution error**\)的代价。 在练习5.3中，将表明如果最可能类的概率低于$1 - \frac{\lambda_r}{\lambda_s}$, 那么最佳操作是选择拒绝操作; 否则你应该选择最可能的类。

![[0082.jpg]]

> 图5.13 对于某些输入空间区域，类别后验是不确定，我们可能不愿意选择1类或2类; 相反，我们可能更喜欢拒绝选项。 基于（Bishop 2006a）的图1.26。

### 5.7.1.3 后验均值最小$l\_2$（二次）损失

对于连续参数，更合适的损失函数是**平方误差**，$l_2$**损失**或**二次损失**，定义为

$$
L(y,a)=(y-a)^2 \tag{5.104}
$$

后验预期损失由下式给出

$$
\rho(a | \boldsymbol{x}) = \mathbb{E} \left[(y-a)^2 | \boldsymbol{x}\right] = \mathbb{E}[y^2|\boldsymbol{x}]-2a\mathbb{E}[y|\boldsymbol{x}] + a^2  \tag{5.105}
$$

因此，最优估计是后验均值：

$$
\dfrac{\partial}{\partial a} \rho(a | \boldsymbol{x})  =  -2\mathbb{E}[y|\boldsymbol{x}] + 2a = 0 \Rightarrow  \hat{y}=\mathbb{E}[y|\boldsymbol{x}]=\int{y p(y|\boldsymbol{x})dy} \tag{5.106}
$$

这通常称为**最小均方误差**估计或**MMSE**估计。

在线性回归问题中，我们有

$$
p(y|\boldsymbol{x},\boldsymbol{\theta})=\mathcal{N}(y|\boldsymbol{x}^T \boldsymbol{w},\sigma^2) \tag{5.107}
$$

在这种情况下，给出一些训练数据$\mathcal{D}$的最佳估计由下式给出

$$
\mathbb{E}[y | \boldsymbol{x},\mathcal{D}] = \boldsymbol{x}^T \mathbb{E}[\boldsymbol{w}|\mathcal{D}] \tag{5.108}
$$

也就是说，我们只要插入后验均值参数估计。 请注意，无论我们使用什么先验$\boldsymbol{w}$，这都是最佳的。

### 5.7.1.4 后验中位数最小$l\_1$（绝对）损失

$l_2$损失以二次方式惩罚与真值的偏差，因此对异常值敏感。 更强大的替代方案是**绝对**或$l_1$**损失**，$L(y,a)= | y - a |$ （见图5.14）。 最佳估计是后验中位数，即，是一个值$a$使得$P(y \lt a | \boldsymbol{x})= P(y\le a|\boldsymbol{x})= 0.5$。 有关证明，请参见练习5.9。

![[0083.jpg]]

> 图5.14 （a-c）绘制$L(y,a)= | y - a |^q$ V.S. \| y - a \| 对$q = 0.2$，$q = 1$和$q = 2$。 由_lossFunctionFig_生成的图。

### 5.7.1.5 监督学习

考虑预测函数$\delta:\mathcal{X}\to \mathcal{Y}$，并假设我们有一些成本函数$l(y,y^{'})$，它给出了当真值是$y^{'}$,预测$y$的成本。 当未知自然状态为$\boldsymbol{\theta}$（数据生成机制的参数）时，我们可以定义采取动作$\delta$（即使用此预测器）所引起的损失如下：

$$
L(\boldsymbol{\theta},\delta) \overset{\Delta}{=} \mathbb{E}_{(\boldsymbol{x},y) \sim p(\boldsymbol{x},y|\boldsymbol{\theta})} [l(y, \delta(\boldsymbol{x}))] = \sum_{\boldsymbol{x}}{\sum_y{L(y,\delta(\boldsymbol{x}))p(\boldsymbol{x},y|\boldsymbol{\theta})}} \tag{5.109}
$$

这称为**泛化误差**\(**generalization error**\)。 我们的目标是尽量减少后期预期的损失

$$
\rho(\delta|\mathcal{D}) = \int{p(\boldsymbol{\theta}|\mathcal{D})L(\boldsymbol{\theta},\delta)d\boldsymbol{\theta}}  \tag{5.110}
$$

这应该与公式6.47中定义的频率风险形成对比。

## 5.7.2 假阳性与假阴性权衡

在本节中，我们将重点放在二元决策问题上，例如假设检验，两类分类，对象/事件检测等。我们可以做出两种类型的错误：**假阳**（**false positive**,又称**误报**），当我们估计$\hat{y} = 1$但实际是$y = 0$时出现; 或**假阴**（ **false negative**, 又称**错过检测**），当我们估计$\hat{y} = 0$但实际是$y = 1$时出现。 0-1损失等价地处理这两种错误。 但是，我们可以考虑以下更一般的损失矩阵：

|  | $\hat{y}=1$ | $\hat{y}=0$ |
| :---: | :---: | :---: |
| $y=1$ | 0 | $L_{FN}$ |
| $y=0$ | $L_{FP}$ | 0 |

其中$L_{FN}$是假阴的成本，而$L_{FP}$是假阳的成本。 两种可能行为的后验预期损失由下式给出

$$
\begin{aligned}
\rho(\hat{y}=0|\boldsymbol{x})=L_{FN}p(y=1|\boldsymbol{x})  \\
\rho(\hat{y}=1|\boldsymbol{x})=L_{FP}p(y=0|\boldsymbol{x}) 
\end{aligned} \tag{5.111-112}
$$

因此我们应该选择$\hat{y} = 1$ 当且仅当

$$
\begin{aligned}
\rho(\hat{y}=0|\boldsymbol{x})>&\rho(\hat{y}=1|\boldsymbol{x})  \\
\dfrac{p(y=1|\boldsymbol{x})}{p(y=0|\boldsymbol{x})}>&\dfrac{L_{FP}}{L_{FN}} 
\end{aligned} \tag{5.113-114}
$$

如果$L_{FN} = c L_{FP}$，很容易证明（练习5.10）我们应该选择$\hat{y} = 1$ 当且仅当 $p(y=1|\boldsymbol{x})/p(y=0|\boldsymbol{x})>\tau$，其中$\tau= c /(1+c)$（另见（Muller等，2004））。 例如，如果假阴成本是假阳性的两倍，那么c = 2，那么我们在宣布阳性之前使用2/3的决策阈值。

下面我们讨论ROC曲线，它提供了一种研究FP-FN权衡的方法，而无需选择特定的阈值。

### 5.7.2.1 ROC曲线及其一切

假设我们正在解决二元决策问题，例如分类，假设检验，对象检测等。另外，假设我们有一个标记数据集，$\mathcal{D} = \{(x_i,y_i)\}$。 设$\delta(x)= \mathbb{I}(f(\boldsymbol{x})>\tau)$是我们的决策规则，其中$f(\boldsymbol{x})$是$y = 1$的置信度量（这应该与$p(y=1|\boldsymbol{x})$单调相关， 但不需要是概率），$\tau$是一些阈值参数。 对于每个给定的$\tau$值，我们可以应用我们的决策规则并计算出现的真阳，假阳，真阴和假阴的数量，如表5.2所示。 该错误表称为**混淆矩阵**\(**confusion matrix**\)。

| 估计$\Downarrow$      实际$\Rightarrow$ | 1 | 0 | 汇总 |
| :---: | :---: | :---: | :---: |
| 1 | TP | FP | $\hat{N}_+$ =TP+FP |
| 0 | FN | TN | $\hat{N}_-$ =FN+TN |
| 汇总 | $N_+$ =TP+FN | $N_-$ =FP+TN | N=TP+FP+FN+TN |

> 表 5.2 可从混淆矩阵导出的量。 $N_+$是实际的阳数，$\hat{N}_+$是估计的阳数，$N_-$是实际阴数，$\hat{N}_-$是估计的阴数。

|  | $y=1$ | $y=0$ |
| :--- | :--- | :--- |
| $\hat{y}=1$ | $TP/N_+$ =真阳率\(TPR\)=敏感性=召回率 | $FP/N_-$ =假阳率\(FPR\)=I型 |
| $\hat{y}=0$ | $FN/N_+$ =假阴率\(FNR\)=错过率=II型 | $TN/N_-$ =真阴率\(TNR\)=特异性 |

> 表 5.3 从混淆矩阵估计$p(\hat{y}|y)$。 缩写：FNR =假阴率，FPR =假阳率，TNR =真阴率，TPR =真阳率。

从该表中，我们可以通过使用$TPR = TP / N_+ \approx p(\hat{y} = 1 | y = 1)$来计算**真阳率**（TPR），也称为**灵敏度**，**召回率**或**命中率**。 我们还可以通过使用$FPR = FP /N_- \approx p(\hat{y} = 1 | y = 0)$来计算**误报率**（FPR），也称为**误报率**或**I型错误率**。 这些和其他定义总结在表5.3和5.4中。 我们可以以我们选择的任何方式组合这些错误来计算损失函数。

然而，我们可以将检测器运行一组阈值，然后将TPR与FPR绘制为τ的隐函数，而不是计算固定阈值τ的TPR和FPR。 这被称为**接收者操作特征**\(**receiver operating characteristic**\)或**ROC**曲线。 有关示例，请参见图5.15（a）。 任何系统都可以通过设置$\tau= 1$来实现左下角的点（FPR = 0，TPR = 0），从而将所有内容分类为负数; 类似地，任何系统都可以通过设置$\tau= 0$来实现右上角的点（FPR = 1，TPR = 1），从而将所有内容分类为正数。 如果系统在机会级别\( chance level\)执行，那么我们可以通过选择适当的阈值来实现对角线TPR = FPR上的任何点。 完美地将正数与负数分开的系统具有可以实现左上角的阈值（FPR = 0，TPR = 1）; 通过改变阈值，这样的系统将“拥抱”左轴，然后“拥抱”顶轴，如图5.15（a）所示。

ROC曲线的质量通常使用**曲线下面积**\(**area under the curve**\)或**AUC**汇总为单个数字。 AUC分数越高越好; 最大值显然是1.使用的另一个汇总统计量是等**误差率**\(**equal error rate**\)或**EER**，也称为**交叉率**\(**cross over rate**\)，定义为满足FPR = FNR的值。 由于FNR = 1 - TPR，我们可以通过从左上角到右下角绘制一条线来计算EER，并查看它与ROC曲线相交的位置（参见图5.15（a）中的点A和B）。 较低的EER分数更好; 最小值显然是0。

![[0084.jpg]]

> 图5.15 （a）两个假设分类系统的ROC曲线。 A优于B.当我们改变阈值$\tau$时，我们绘制真阳性率（TPR）与假阳性率（FPR）。 我们还指出了红色和蓝色点的等错误率（EER），以及分类器B的曲线下面积（AUC）。（b）两个假设分类系统的精确回忆曲线。 A优于B.由_PRhand_生成的图。

|  | $y=1$ | $y=0$ |
| :---: | :---: | :---: |
| $\hat{y}=1$ | $TP/\hat{N}_+$ =精度=PPV | $FP/\hat{N}_+$ =FDP |
| $\hat{y}=0$ | $FN/\hat{N}_-$ | $TN/\hat{N}_-$ =NPV |

> 表 5.4 从混淆矩阵估计$p(y | \hat{y})$。 缩写：FDP =错误发现概率，NPV =阴性预测值，PPV =阳性预测值，

### 5.7.2.2 精确召回曲线\(Precision recall curves\)

当试图检测罕见事件（例如检索相关文档或在图像中找到面部）时，反例的量非常大。 因此，将${\rm TPR} = {\rm TP} / N_+$与${\rm FPR} = {\rm FP} / N_-$进行比较不是非常有用的，因为**FPR**将非常小。 因此，**ROC**曲线中的所有“动作”都将发生在最左侧。 在这种情况下，通常将**TPR**与**假阳**的数量进行比较，而不是与**误报率**进行比较。

但是，在某些情况下，“否定”的概念并不是很明确。 例如，当检测图像中的对象时（参见第1.2.1.3节），如果检测器通过分类补丁工作，则检查的补丁数量\(并且进而真阴性的数量\) 是算法的参数，而不是 问题定义。 因此，我们希望使用仅涉及正例因素的措施。

**精度**\(**precision**\)定义为${\rm TP} / \hat{N}_+ = p(y = 1 | \hat{y} = 1)$，并且**召回**\(**recall**\)定义为${\rm TP} / N_+ = p(\hat{y} = 1 | y = 1)$。 **精度**测量我们估计为阳的真阳部分，并**召回**测量我们实际检测到的真阳部分。 如果$\hat{y}_i \in \{0,1\}$是预测标签，并且$y_i \in \{0,1\}$是真实标签，我们可以使用下式估计精度和召回

$$
P=\dfrac{\sum_i{y_i \hat{y}_i}}{\sum_i{\hat{y}_i}}, R=\dfrac{\sum_i{y_i \hat{y}_i}}{\sum_i{y_i}}\tag{5.115}
$$

**精确召回曲线**\(**precision recall curve**\)是我们改变阈值$\tau$时精度与召回的关系图。 见图5.15（b）。 拥抱右上角是最好的。

该曲线可以使用平均精度（平均召回）来概括为单个数字，其近似于曲线下面积。 或者，可以引用固定召回级别的精度，例如召回的第一个K = 10个实体的精度。 这称为**K平均精度**\(**average precision at K**\)得分。 在评估信息检索系统时广泛使用该度量。

### 5.7.2.3  F分数\*

对于固定阈值，可以计算单个精度和召回值。 这些通常组合成一个统计，称为**F分数**，或**F1分数**，这是精度和召回的调和平均值：

$$
F_1 \overset{\Delta}{=}\dfrac{2}{1/P + 1/R}=\dfrac{2 P R}{P + R} \tag{5.116}
$$

使用公式5.115，我们可以将其写为

$$
F_1 = \dfrac{2 \sum_{i=1}^N{y_i \hat{y}_i}}{\sum_{i=1}^N{\hat{y}_i} + \sum_{i=1}^N{y_i}} \tag{5.117}
$$

这是信息检索系统中广泛使用的措施。

要理解为什么我们使用调和均值而不是算术平均值$(P + R)/ 2$，请考虑以下情形。 假设我们召回所有条目，即$R = 1$。 精度将由**患病率**\(**prevalence**\)$p(y = 1)$给出。 假设患病率较低，比如$p(y = 1)=10^{-4}$ 。 P和R的算术平均值由$(P + R)/ 2 =(10^{-4} + 1)/2 \approx 50$%给出。 相比之下，该策略的调和均值仅为$\frac{2\times 10^{-4}\times 1}{ 1 + 10^{-4}} \approx 0.2$%。

![[0085.jpg]]

> 表5.5 宏观和微观平均之间差异的插图。 $y$是真正的标签，$\hat{y}$是估计的标签。 在该示例中，宏观平均精度为\[10 /（10 + 10）+90 /（10 + 90）\] / 2 =（0.5 + 0.9）/ 2 = 0.7。 微观平均精度为100 /（100 + 20）≈0.83。 基于（Manning等人，2008）的表13.7。

在多类情况下（例如，对于文档分类问题），有两种方法可以推广$F_1$分数。 第一个被称为**宏观平均F1**\(**macro-averaged F1**\)，并被定义为$\sum_{c=1}^C{F_1(c)}/ C$，其中$F_1(c)$是在将c类与所有其他类别区分开来的任务上获得的$F_1$分数。 另一个被称为**微观平均F1**\(**micro-averaged F1**\)，并被定义为我们汇集每个类的列联表中的所有计数作为$F_1$分数。

表5.5给出了一个说明差异的工作实例。 我们看到1级的精度是0.5，而2级的精度是0.9。 因此，宏观平均精度为0.7，而微观平均精度为0.83。 后者更接近2级的精度而不是1级的精度，因为2级比1级大5倍。为了给每个等级赋予相同的权重，使用宏观平均。

### 5.7.2.4 错误发现率\(False discovery rates\)\*

假设我们试图使用某种高通量测量装置发现罕见的现象，例如基因表达微阵列或射电望远镜。 我们需要做出形式为$p(y_i = 1 | \mathcal{D})>\tau$的许多二元决策，其中$\mathcal{D} = \{\boldsymbol{x}_i\}_{i=1}^N$并且$N$可能很大。 这称为**多重假设检验**\(**multiple hypothesis testing**\)。 请注意，与标准二元分类的区别在于我们基于所有数据对$y_i$进行分类，而不仅仅基于$\boldsymbol{x}_i$。 所以这是一个同时发生的分类问题，我们可能希望比一系列单独的分类问题做得更好。

我们应该如何设定阈值$\tau$？ 一种自然的方法是最小化期望的假阳数。 在贝叶斯方法中，这可以计算如下：

$$
{\rm FD}(\tau,\mathcal{D})\overset{\Delta}{=}\sum_i{\underbrace{(1-p_i)}_{pr. error}\underbrace{\mathbb{I}(p_i>\tau)}_{discovery}} \tag{5.118}
$$

其中$p_i \overset{\Delta}{=} p(y_i = 1 | \mathcal{D})$是你相信这个对象表现出有问题的现象。 然后，我们将后验预期**错误发现率**\(**False discovery rates**\)定义如下：

$$
{\rm FDR}(\tau,\mathcal{D})={\rm FD}(\tau,\mathcal{D})/N(\tau,\mathcal{D}) \tag{5.119}
$$

其中$N(\tau,\mathcal{D})= \sum_i{\mathbb{I}(p_i>\tau)}$是发现的项数。 给定期望FDR容差，例如$\alpha= 0.05$，可以调整$\tau$来实现这一点; 这被称为控制FDR的**直接后验概率方法**\(**direct posterior probability approach**\)（Newton等，2004; Muller等，2004）。

为了控制FDR，估计$p_i$的联合分布是非常有用的（例如，使用分层贝叶斯模型，如第5.5节），而不是独立地估计。 这样可以汇集统计强度，从而降低FDR。 例如，参见（Berry和Hochberg 1999）以获得更多信息。

## 5.7.3 其他主题\*

在本节中，我们简要介绍一些与贝叶斯决策理论相关的其他主题。 我们没有足够的空间详细介绍，但我们提供了相关文献的指示。

### 5.7.3.1 上下文强盗\(Contextual bandits\)

**单臂强盗**\(**one-armed bandit**\)是世界各地赌场中出现的老虎机\(slot machine\)的俗称。 游戏是这样的：你插入一些钱，拉一臂，等待机器停止; 如果你很幸运，你会赢一些钱。 现在假设有K组这样的机器可供选择。 你应该使用哪一个？ 这被称为**多臂强盗**\(**multi-armed bandit**\)，并且可以使用贝叶斯决策理论建模：存在K个可能的动作，并且每个动作具有未知的奖励（支付函数）$r_k$。 通过维持信念状态$p(r_{1:K} | \mathcal{D})=\prod_k{p(r_k | \mathcal{D})}$，可以设计最优策略; 这可以汇编成一系列的**Gittins指数**（Gittins 1989）。 这最佳地解决了**探索-开发**\(**exploration-exploitation**\)权衡，指示了在成为赢家之前每次动作应该尝试的次数。

现在考虑一个扩展，其中每个手臂和玩家都有一个相关的特征向量; 所有这些特征记作$\boldsymbol{x}$。 这被称为**上下文强盗**\(**Contextual bandits**\)（参见例如（Sarkar 1991; Scott 2010; Li等人2011））。 例如，“手臂”可以表示我们想要向用户显示的广告或新闻文章，并且这些特征可以表示这些广告或文章的属性，例如一袋文字，以及用户的属性，例如 人口统计学。 如果我们假设将一个线性模型用于奖励，$r_k =\boldsymbol{\theta}_k^T \boldsymbol{x}$，我们可以保持每个臂参数的分布，$p(\boldsymbol{\theta}_k | \mathcal{D})$，其中$\mathcal{D}$是一个形如$(a,\boldsymbol{x},r)$的元组序列，其说明哪个手臂被拉动，其特征是什么，以及结果是什么（例如，如果用户点击广告则$r = 1$，否则$r = 0$）。 我们将在后面的章节中讨论从线性和逻辑斯蒂回归模型计算$p(\boldsymbol{\theta}_k | \mathcal{D})$的方法。

给定一个后验，我们必须决定采取什么行动。 一种常见的启发式方法，即**UCB**（代表“上置信边界”），是按最大下式来采取行动

$$
k^*=\underset{k=1:K}{\rm argmax} \ \mu_k+\lambda \sigma_k \tag{5.120}
$$

其中$\mu_k= \mathbb{E} [r_k | \mathcal{D}], \sigma_k^2= {\rm var} [r_k | \mathcal{D}]$，$\lambda$是一个用于权衡探索-开发的调整参数。 直觉是我们应该选择我们认为好的行动（$\mu_k$很大）和/或我们不确定的行动（$\sigma_k$很大）。

一种更简单的方法，称为**汤普森采样**\(**Thompson sampling**\)，如下所述。 在每一步，我们选择动作$k$的概率等于其作为最优动作的概率：

$$
p_k = \int{\mathbb{I}\left(\mathbb{E}[r|a,\boldsymbol{x},\boldsymbol{\theta}]=\underset{a^{'}}{\rm max}\ \mathbb{E}[r|a^{'},\boldsymbol{x},\boldsymbol{\theta}]\right) p(\boldsymbol{\theta}|\mathcal{D}) d\boldsymbol{\theta} } \tag{5.121}
$$

我们可以通过绘制单个样本后验$\boldsymbol{\theta}^t \sim p(\boldsymbol{\theta}|\mathcal{D})$，然后选择$k^* = {\rm argmax}_k \ \mathbb{E}[r | \boldsymbol{x}，k，\boldsymbol{\theta}^t]$来近似。 尽管它很简单，但它已被证明效果很好（Chapelle和Li 2011）。

### 5.7.3.2 效用理论

假设我们是一名医生，试图决定是否对患者进行手术。 我们想象有三种自然状态：患者没有癌症，患者患有肺癌，或患者患有乳腺癌。 由于动作和状态空间是离散的，我们可以将损失函数$L(\theta,a)$表示为**损失矩阵**\(**loss matrix**\)，如下所示：

|  | 手术 | 无须手术 |
| :---: | :---: | :---: |
| 没有癌症 | 20 | 0 |
| 肺癌 | 10 | 50 |
| 乳腺癌 | 10 | 60 |

这些数字反映了这样一个事实：当患者患有癌症时不进行手术是非常糟糕的（由于癌症的类型而损失50或60），因为患者可能死亡; 当患者没有患癌症时不进行手术，不会造成任何损失（0）; 当患者没有患癌症时进行手术是浪费（损失20）; 当患者患有癌症时进行手术是痛苦但必要的（10）。

很自然地会问这些数字来自哪里。 最终，它们代表了一位狡猾的医生的个人**偏好**或价值观，并且有点武断：正如有些人喜欢巧克力冰淇淋而其他人更喜欢香草，没有“正确”的损失/效用功能。 然而，可以示出（参见例如（DeGroot 1970））可以将任何一致的偏好集转换为标量损失/效用函数。 请注意，效用可以在任意比例上测量，例如美元，因为它只是重要的相对值。

### 5.7.3.3 顺序决策理论

到目前为止，我们一直专注于**一次性决策问题**\(**one-shot decision problems**\)，我们只需做出一个决定然后游戏结束。 在第10.6节中，我们将其概括为多阶段或顺序决策问题。 这些问题经常出现在许多商业和工程设置中。 这与强化学习问题密切相关。 但是，对这一点的进一步讨论超出了本书的范围。

[**返回本章目录**]({{< relref "/docs/mlapp/05bayesian_statistics" >}})

