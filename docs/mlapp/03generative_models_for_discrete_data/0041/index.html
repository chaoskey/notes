<!DOCTYPE html>
<html lang="cn">

<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="3.3 贝塔-二项模型"><meta property="og:title" content="3.3 贝塔-二项模型" />
<meta property="og:description" content="返回本章目录
在给定一离散观察序列的情况下, 数字游戏涉及从有限假设空间推断出离散变量的分布, 
  
    

    
    
    
    
    
    
    
    
  





  \(h \in \mathcal{H}\)

。这使计算变得特别简单：我们只需要求和，乘和除。然而，在许多应用中，未知参数是连续的，因此假设空间是



  \(\mathbb{R}^K\)

的某个子集, 其中



  \(K\)

是参数的个数. 这使数学变得复杂，因为我们必须用积分代替和。但是，基本思路是一样的。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://chaoskey.gitee.io/notes/docs/mlapp/03generative_models_for_discrete_data/0041/" /><meta property="article:section" content="docs" />
<meta property="article:published_time" content="2019-06-29T20:20:35&#43;08:00" />
<meta property="article:modified_time" content="2019-06-29T20:20:35&#43;08:00" />

<title>3.3 贝塔-二项模型 | 学习笔记</title>
<link rel="icon" href="/notes/favicon.png" type="image/x-icon">


<link rel="stylesheet" href="/notes/book.min.0253b76936e9496c1a48e74d90cdc268fd0e96366c60a1f43994801cc334588a.css" integrity="sha256-AlO3aTbpSWwaSOdNkM3CaP0OljZsYKH0OZSAHMM0WIo=">


<script defer src="/notes/cn.search.min.f734b55049115fd51afdc9f74cd5d979d8ff31b218dc3721a5f645b9690cfef4.js" integrity="sha256-9zS1UEkRX9Ua/cn3TNXZedj/MbIY3DchpfZFuWkM/vQ="></script>

<!--
Made with Book Theme
https://github.com/alex-shpak/hugo-book
-->

  
</head>

<body>
  <input type="checkbox" class="hidden" id="menu-control" />
  <main class="container flex">
    <aside class="book-menu">
      
  <nav>
<h2 class="book-brand">
  <a href="/notes"><img src="/notes/logo.png" alt="Logo" /><span>学习笔记</span>
  </a>
</h2>


<div class="book-search">
  <input type="text" id="book-search-input" placeholder="搜索" aria-label="搜索" maxlength="64" data-hotkeys="s/" />
  <div class="book-search-spinner spinner hidden"></div>
  <ul id="book-search-results"></ul>
</div>









  










    
    



<ul>
<li><a href="/notes/posts/"><strong>杂事记录</strong></a></li>
<li><a href="/notes/docs/fem/"><strong>有限元法自动求解微分方程</strong></a></li>
<li><a href="/notes/docs/julia/"><strong>基于Julia科学计算</strong></a></li>
<li><a href="/notes/docs/theophy/"><strong>理论物理学习笔记</strong></a></li>
<li><a href="/notes/docs/diffgeo/"><strong>微分几何笔记</strong></a></li>
<li><a href="/notes/docs/mlapp/"><strong>机器学习：概率视角</strong></a>
<ul>
<li><a href="/notes/docs/mlapp/01introduction/">第一章 导论</a></li>
<li><a href="/notes/docs/mlapp/02probability/">第二章 概率</a></li>
<li><a href="/notes/docs/mlapp/03generative_models_for_discrete_data/">第三章 基于离散数据的生成式模型</a></li>
<li><a href="/notes/docs/mlapp/04gaussian_models/">第四章 高斯模型</a></li>
<li><a href="/notes/docs/mlapp/05bayesian_statistics/">第五章 贝叶斯统计</a></li>
<li><a href="/notes/docs/mlapp/06frequentist_statistics/">第六章 频率派统计</a></li>
<li><a href="/notes/docs/mlapp/07linear_regression/">第七章 线性回归</a></li>
</ul>
</li>
<li><a href="/notes/docs/apm/"><strong>主动投资组合管理</strong></a></li>
</ul>












</nav>




  <script>(function(){var a=document.querySelector("aside.book-menu nav");addEventListener("beforeunload",function(b){localStorage.setItem("menu.scrollTop",a.scrollTop)}),a.scrollTop=localStorage.getItem("menu.scrollTop")})()</script>


 
    </aside>

    <div class="book-page">
      <header class="book-header">
        
  <div class="flex align-center justify-between">
  <label for="menu-control">
    <img src="/notes/svg/menu.svg" class="book-icon" alt="Menu" />
  </label>

  <strong>3.3 贝塔-二项模型</strong>

  <label for="toc-control">
    <img src="/notes/svg/toc.svg" class="book-icon" alt="Table of Contents" />
  </label>
</div>


  
    <input type="checkbox" class="hidden" id="toc-control" />
    <aside class="hidden clearfix">
      
  <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#331-拟然">3.3.1 拟然</a></li>
        <li><a href="#332-先验">3.3.2 先验</a></li>
        <li><a href="#333-后验">3.3.3 后验</a>
          <ul>
            <li><a href="#3331-后验均值和众数mode">3.3.3.1 后验均值和众数(mode)</a></li>
            <li><a href="#3332-后验方差">3.3.3.2 后验方差</a></li>
          </ul>
        </li>
        <li><a href="#334-后验预测分布">3.3.4 后验预测分布</a>
          <ul>
            <li><a href="#3341-过拟合和黑天鹅悖论">3.3.4.1 过拟合和黑天鹅悖论</a></li>
            <li><a href="#3341-预测多个未来试验的结果">3.3.4.1 预测多个未来试验的结果</a></li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</nav>


    </aside>
  
 
      </header>

      

<nav class="post-pagination">
  
  <a class="newer-posts" href="https://chaoskey.gitee.io/notes/docs/mlapp/03generative_models_for_discrete_data/0042/">
    下一页<br>3.4 狄利克雷-多项模型
  </a>
  
  
  <a class="older-posts" href="https://chaoskey.gitee.io/notes/docs/mlapp/03generative_models_for_discrete_data/0040/">
      上一页<br>3.2 贝叶斯概念学习
  </a>
  
</nav>

<hr>

<article class="markdown">
  <h1>
    <a href="/notes/docs/mlapp/03generative_models_for_discrete_data/0041/">3.3 贝塔-二项模型</a>
  </h1>
  

<div>

  <h5>2019-06-29</h5>


<div>

  
    |
    
      <a href="/notes/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">机器学习</a>
      
    |
  

  
    |
    
      <a href="/notes/tags/%E6%8B%9F%E7%84%B6">拟然</a>
      , 
      <a href="/notes/tags/%E5%85%88%E9%AA%8C">先验</a>
      , 
      <a href="/notes/tags/%E5%90%8E%E9%AA%8C">后验</a>
      , 
      <a href="/notes/tags/%E5%9D%87%E5%80%BC">均值</a>
      , 
      <a href="/notes/tags/%E4%BC%97%E6%95%B0">众数</a>
      , 
      <a href="/notes/tags/%E6%96%B9%E5%B7%AE">方差</a>
      , 
      <a href="/notes/tags/%E5%88%86%E5%B8%83">分布</a>
      , 
      <a href="/notes/tags/%E6%8B%9F%E5%90%88">拟合</a>
      , 
      <a href="/notes/tags/%E6%82%96%E8%AE%BA">悖论</a>
      , 
      <a href="/notes/tags/%E9%A2%84%E6%B5%8B">预测</a>
      
    |
  




    <a href="https://gitee.com/chaoskey/notes/blob/master/content/docs/mlapp/03generative_models_for_discrete_data/0041.md#blob-comment" target="_blank" rel="noopener">
      <img src="/notes/svg/edit.svg" class="book-icon" alt="Comment" />
      评论
    </a>


</div>


</div>

<p><a href="/notes/docs/mlapp/03generative_models_for_discrete_data/"><strong>返回本章目录</strong></a></p>
<p>在给定一离散观察序列的情况下, 数字游戏涉及从有限假设空间推断出离散变量的分布, 
  
    

    <link rel="stylesheet" href="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
    
    
    <script defer src="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
    
    
    <script defer src="https://cdn.bootcss.com/KaTeX/0.11.1/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
            onload="renderMathInElement(document.body,
                {delimiters: [{left: '$$\n', right: '\n$$', display: true}, {left: '$$', right: '$$', display: false}, 
                              {left: '\\[', right: '\\]', display: true}, {left: '\\(', right: '\\)', display: false}]});"></script>
    
  




<span class="katex">
  \(h \in \mathcal{H}\)
</span>
。这使计算变得特别简单：我们只需要求和，乘和除。然而，在许多应用中，未知参数是连续的，因此假设空间是


<span class="katex">
  \(\mathbb{R}^K\)
</span>
的某个子集, 其中


<span class="katex">
  \(K\)
</span>
是参数的个数. 这使数学变得复杂，因为我们必须用积分代替和。但是，基本思路是一样的。</p>
<p>我们将通过考虑一系列观察到的硬币投掷来推断硬币出现头部的可能性的问题来说明这一点。虽然这看似微不足道，但事实证明，这个模型构成了我们将在本书后面考虑的许多方法的基础，包括朴素的贝叶斯分类器，马尔可夫模型等。这在历史上很重要，因为它是一个例子。在贝叶斯1763年的原始论文中进行了分析。（贝叶斯的分析随后由皮埃尔·西蒙·拉普拉斯推广，创造了我们现在所说的“贝叶斯法则” - 参见（Stigler, 1986）了解更多历史细节。）</p>
<p>我们将遵循现在熟悉的指定拟然和先验的方法，并导出后验和后验预测。</p>
<h2 id="331-拟然">3.3.1 拟然</h2>
<p>假设


<span class="katex">
  \(X_i \sim {\rm Ber}(\theta)\)
</span>
，其中


<span class="katex">
  \(X_i=1\)
</span>
代表“正面”，


<span class="katex">
  \(X_i=0\)
</span>
代表“反面”，并且


<span class="katex">
  \(\theta \in [0,1]\)
</span>
是速率参数（&ldquo;正面&quot;的概率）。如果数据是独立同分布(i.i.d)，那么拟然形如下式:</p>



<span class="katex">
  \[
p( \mathcal{D} | \theta) = \theta^{N_1} (1-\theta)^{N_0} \tag{3.11}
\]
</span>

<p>其中我们有


<span class="katex">
  \(N_1=\sum_{i=1}^N {\mathbb{I}(x_i=1)}\)
</span>
个&quot;正面&rdquo; 和


<span class="katex">
  \(N_0=\sum_{i=0}^N {\mathbb{I}(x_i=1)}\)
</span>
个&quot;反面&quot;。这两个计数被称为数据的<strong>充分统计</strong>，因为这是我们需要知道的关于


<span class="katex">
  \(\mathcal{D}\)
</span>
推断出


<span class="katex">
  \(\theta\)
</span>
的所有内容。 （另一组充分统计的数据是


<span class="katex">
  \(N_1\)
</span>
和


<span class="katex">
  \(N=N_0 + N_1\)
</span>
）。</p>
<p>更正式地，我们称


<span class="katex">
  \(s(\mathcal{D})\)
</span>
是数据


<span class="katex">
  \(\mathcal{D}\)
</span>
的充分统计, 如果


<span class="katex">
  \(p(\theta | \mathcal{D})=p(\theta | s(data))\)
</span>
。如果我们使用一个均匀先验, 这等价于说, 


<span class="katex">
  \(p(\mathcal{D} | \theta) \propto p(s(\mathcal{D}) | \theta)\)
</span>
。因此，如果有两个具有相同充分统计的数据集，我们会推断出相同的


<span class="katex">
  \(\theta\)
</span>
值。</p>
<p>现在假设数据由&quot;正面&quot;计数


<span class="katex">
  \(N_1\)
</span>
 和固定数观察


<span class="katex">
  \(N=N_1+N_0\)
</span>
组成。在在这种情况下，我们有


<span class="katex">
  \(N_1 \sim {\rm Bin}(N,\theta)\)
</span>
，其中 


<span class="katex">
  \({\rm Bin}\)
</span>
表示二项分布，其具有以下pmf(概率分布)：</p>



<span class="katex">
  \[
{\rm Bin}(k | n, \theta)  \overset{\Delta}{=} \binom{n}{k} \theta^k (1-\theta)^{(n-k)} \tag{3.12}
\]
</span>

<p>由于


<span class="katex">
  \(\binom{n}{k}\)
</span>
 是


<span class="katex">
  \(\theta\)
</span>
无关的常数，二项采样模型的拟然等同与伯努利模型的拟然。因此，我们对


<span class="katex">
  \(\theta\)
</span>
做出的任何推论都是相同的, 无论我们是观察


<span class="katex">
  \(\mathcal{D}=(N_1,N)\)
</span>
的计数, 还是观察序列


<span class="katex">
  \(\mathcal{D}=\{x_1,\dots,x_N\}\)
</span>
的计数。</p>
<h2 id="332-先验">3.3.2 先验</h2>
<p>我们需要一个支持区间


<span class="katex">
  \([0,1]\)
</span>
的先验。为了使数学上更容易，如果先验和拟然具有相同的形式, 那会很方便的, 比如形如:</p>



<span class="katex">
  \[
p(\theta) \propto  \theta^{\gamma_1} (1-\theta)^{\gamma_2} \tag{3.13}
\]
</span>

<p>其中, 


<span class="katex">
  \(\gamma_1\)
</span>
和


<span class="katex">
  \(\gamma_2\)
</span>
是一些特定的先验参数。如果这样的话，那么我们可以很容易通过简单地增加指数来计算后验:</p>



<span class="katex">
  \[
p(\theta | \mathcal{D}) \propto p(\mathcal{D} | \theta) p(\theta)= \theta^{N_1} (1-\theta)^{N_0} \ \theta^{\gamma_1} (1-\theta)^{\gamma_2} = \theta^{N_1 + \gamma_1} (1-\theta)^{N_0 + \gamma_2} \tag{3.14}
\]
</span>

<p><img src="" alt="0062.jpg"></p>
<blockquote>
<p>图3.6 （a）使用具有充分统计量


<span class="katex">
  \(N_1=3,N_0=17\)
</span>
的二项拟然来更新


<span class="katex">
  \({\rm Beta}(2,2)\)
</span>
以生成一个


<span class="katex">
  \({\rm Beta}(5,9)\)
</span>
的后验。 （b）使用具有充分统计量


<span class="katex">
  \(N_1=11,,N_0=13\)
</span>
的二项拟然来更新


<span class="katex">
  \({\rm Beta}(5,2)\)
</span>
以生成一个


<span class="katex">
  \({\rm Beta}(16,15)\)
</span>
的后验。</p>
</blockquote>
<p>当在先验和后验具有相同的形式时，我们说，这个先验是相关拟然的<strong>共轭先验</strong>。共轭先验被广泛使用，因为它们简化了计算，并且易于解释， 正如上所示。</p>
<p>在伯努利的情况下，共轭先验是一个


<span class="katex">
  \(\beta\)
</span>
分布，就是我们在第2.4.5节中将会遇到的:</p>



<span class="katex">
  \[
{\rm Beta}(\theta | a,b) \propto \theta^{a-1} (1-\theta)^{b-1} \tag{3.15}
\]
</span>

<p>这个先验的参数被称为<strong>超参数</strong>。我们可以设置它们以编码我们先验信念。例如，为了编码我们的信念: 


<span class="katex">
  \(\theta\)
</span>
均值为0.7，标准差为0.2，我们可以设置


<span class="katex">
  \(a=2.957\)
</span>
和


<span class="katex">
  \(b=1.275\)
</span>
（练习3.15）。或编码我们的信念: 


<span class="katex">
  \(\theta\)
</span>
的均值为0.15，并且有一定概率落在区间


<span class="katex">
  \((0.05,0.30)\)
</span>
上，那么我们可以找到


<span class="katex">
  \(a=4.5\)
</span>
和


<span class="katex">
  \(a=25.5\)
</span>
 （练习3.16）。</p>
<p>如果我们对


<span class="katex">
  \(\theta\)
</span>
 一无所知, 除了知道其落在


<span class="katex">
  \([0,1]\)
</span>
中。 我们可以使用均匀先验，这是一种无信息先验之（详见5.4.2节）。均匀分布可以用的


<span class="katex">
  \(\beta\)
</span>
分布表示, 只要取


<span class="katex">
  \(a=b=1\)
</span>
 。</p>
<h2 id="333-后验">3.3.3 后验</h2>
<p>如果我们通过


<span class="katex">
  \(\beta\)
</span>
先验乘上拟然, 可得到如下的后验(依照方程3.14)：</p>



<span class="katex">
  \[
p(\theta | \mathcal{D}) \propto  {\rm Bin}(N_1 | \theta,N_0+N_1) {\rm Beta}(\theta | a,b) \propto {\rm Beta}(\theta | N_1+a,N_0+b)  \tag{3.16}
\]
</span>

<p>特别是，后验是通过将先前的超参数加上经验计数获得的。因此，超参数称为 <strong>伪计数</strong>(pseudo counts)。先验的强度，也称为先验的<strong>有效样本大小</strong>(effective sample size) ，是伪计数的总和,即


<span class="katex">
  \(a+b\)
</span>
; 这起着类似于数据集大小的作用, 


<span class="katex">
  \(N_1+N_0=N\)
</span>
。</p>
<p>图3.6（a）给出了一个示例，其中我们使用有尖峰的似然函数来更新弱的


<span class="katex">
  \({\rm Beta}(2,2)\)
</span>
，这是对与大样本量而言的; 我们可看到后验与拟然基本一样： 因为数据已经压倒了先验。图3.6（b）给出了一个示例，其中我们也使用尖峰似然函数来更新强的


<span class="katex">
  \({\rm Beta}(5,2)\)
</span>
; 现在我们看到后验是先验和拟然之间的“妥协”。</p>
<p>请注意，顺序更新后验等效于一次性批量更新。为了看清这一点，假设我们有两个数据集


<span class="katex">
  \(\mathcal{D}_a\)
</span>
和


<span class="katex">
  \(\mathcal{D}_b\)
</span>
, 其充分统计量分别是


<span class="katex">
  \(N_1^a,N_0^a\)
</span>
和


<span class="katex">
  \(N_1^b,N_0^b\)
</span>
。设


<span class="katex">
  \(N_1=N_1^a+N_1^b\)
</span>
和


<span class="katex">
  \(N_0=N_0^a+N_0^b\)
</span>
是组合数据集的充分统计。在批量模式中，我们有:</p>



<span class="katex">
  \[
p(\theta | \mathcal{D}_a,\mathcal{D}_b) \propto  {\rm Bin}(N_1 | \theta,N_0+N_1) {\rm Beta}(\theta | a,b) \propto {\rm Beta}(\theta | N_1+a,N_0+b)  \tag{3.17}
\]
</span>

<p>在顺序模式下，我们有:</p>



<span class="katex">
  \[
\begin{aligned}
p(\theta | \mathcal{D}_a,\mathcal{D}_b) & \propto   p(\mathcal{D}_b | \theta) \ p(\theta | \mathcal{D}_a) \\
\quad &  \propto {\rm Bin}(N_1^b | \theta,N_0^b+N_1^b) {\rm Beta}(\theta | N_1^a+a,N_0^a+b)  \\
&\propto {\rm Beta}(\theta | N_1^a+N_1^b+a,N_0^a+N_0^b+b)  
\end{aligned}  \tag{3.18-20}
\]
</span>

<p>这使得贝叶斯推理特别适合<strong>在线学习</strong>，我们将在后面看到。</p>
<h3 id="3331-后验均值和众数mode">3.3.3.1 后验均值和众数(mode)</h3>
<p>根据公式2.62，MAP估计可由下式给出:</p>



<span class="katex">
  \[
\hat{\theta}_{\rm MAP} = \dfrac{a+N_1-1}{a+b+N-2} \tag{3.21}
\]
</span>

<p>如果我们使用均匀先验，那么MAP估计简化成MLE， 这正好是&quot;正面&quot;的经验值:</p>



<span class="katex">
  \[
\hat{\theta}_{\rm MLE} = \dfrac{N_1}{N} \tag{3.22}
\]
</span>

<p>这复合直觉，但它也可以通过应用基础微积分来最大化式3.11中的似然函数推导出来 （练习3.1）。</p>
<p>相比之下，后验均值由下式给出:</p>



<span class="katex">
  \[
\bar{\theta} = \dfrac{a+N_1}{a+b+N} \tag{3.23}
\]
</span>

<p>这种众数(等于MAP)和均值之间的差异将在以后着重证明。</p>
<p>我们现在将展示后验均值是先验均值和MLE的凸组合，它捕捉了后验是我们之前所认为的和数据告诉我们的这两种情况折衷的概念。</p>
<p>令


<span class="katex">
  \(\alpha_0=a+b\)
</span>
 表示先验的<strong>等效样本尺寸</strong>，通过它控制强度，进而先验均值可写成


<span class="katex">
  \(m_1=a/\alpha_0\)
</span>
。然后，后验均值写成:</p>



<span class="katex">
  \[
\mathbb{E}[\theta|\mathcal{D}]=\dfrac{\alpha_0 m_1 + N_1}{N+\alpha_0}=\dfrac{\alpha_0}{N+\alpha_0}m_1+\dfrac{N}{N+\alpha_0} \dfrac{N_1}{N}=\lambda \ m_1+(1-\lambda) \ \hat{\theta}_{\rm MLE}  \tag{3.24}
\]
</span>

<p>其中


<span class="katex">
  \(\lambda = \frac{\alpha_0}{N+\alpha_0}\)
</span>
是先验和后验等效样本尺寸的比率。因此越弱的先验具有越小的


<span class="katex">
  \(\lambda\)
</span>
，进而后验均值越接近MLE。类似可见后验众数是先验众数和MLE的凸组合，并且它也会收敛到MLE。</p>
<h3 id="3332-后验方差">3.3.3.2 后验方差</h3>
<p>均值和众数是点估计，但我们知道能够多大程度信任它, 也是是有用的。后验的方差是衡量这点的一种方法。 Beta后验的方差由下式给出:</p>



<span class="katex">
  \[
{\rm Var}[\theta | \mathcal{D}]=\dfrac{(a+N_1)(b+N_0)}{(a+N_1+b+N_0)^2(a+N_1+b+N_0+1)^2} \tag{3.25}
\]
</span>

<p>如果


<span class="katex">
  \(N\gg a,b\)
</span>
, 我们可以将这个&quot;吓人&quot;的表达式简化成:</p>



<span class="katex">
  \[
{\rm Var}[\theta | \mathcal{D}] \approx \dfrac{N_1 N_0}{N N N} =  \dfrac{\hat{\theta} (1-\hat{\theta})}{N} \tag{3.26}
\]
</span>

<p>其中


<span class="katex">
  \(\hat{\theta}\)
</span>
就是MLE。因此我们估计中的&quot;误差条&quot;（即后验标准差）由下式给出:</p>



<span class="katex">
  \[
\sigma=\sqrt{{\rm Var}[\theta | \mathcal{D}]} \approx \sqrt{\dfrac{\hat{\theta} (1-\hat{\theta})}{N}} \tag{3.27}
\]
</span>

<p>我们看到，不确定性随着比率


<span class="katex">
  \(1/\sqrt{N}\)
</span>
降低而降低 。但是请注意，当


<span class="katex">
  \(\hat{\theta}=0.5\)
</span>
时, 不确定性（方差）最大, 而当


<span class="katex">
  \(\hat{\theta}\)
</span>
接近0或1时最小。这意味着它更容易确保硬币偏置比，以确保它是公平。</p>
<h2 id="334-后验预测分布">3.3.4 后验预测分布</h2>
<p>到目前为止，我们一直关注未知参数的推断。现在让我们把注意力转向预测未来的可观测数据。</p>
<p>考虑在单个未来试验中, 给定


<span class="katex">
  \({\rm Beta}(a,b)\)
</span>
后验, 那么&quot;正面&quot;预测的概率是:</p>



<span class="katex">
  \[
\begin{aligned}
p(\tilde{x} = 1 | \mathcal{D}) & = \int_0^1 {p(x = 1 | \theta)  p(\theta | \mathcal{D}) d \theta}  \\
\quad &  =\int_0^1 {\theta \  {\rm Beta}(\theta | a,b) d \theta} = \mathbb{E}[\theta | \mathcal{D}] = \dfrac{a}{a+b}  
\end{aligned}  \tag{3.28-29}
\]
</span>

<p>由此可见, <strong>正例后验预测分布</strong>可用<strong>后验参数均值</strong>等效插入, 进而完整的<strong>后验预测分布</strong>可写成:


<span class="katex">
  \(p(\tilde{x} | \mathcal{D})={\rm Ber}(\tilde{x} | \mathbb{E}[\theta | \mathcal{D}])\)
</span>
。</p>
<h3 id="3341-过拟合和黑天鹅悖论">3.3.4.1 过拟合和黑天鹅悖论</h3>
<p>我们考虑用MLE近似插入, 即


<span class="katex">
  \(p(\tilde{x} | \mathcal{D})={\rm Ber}(\tilde{x} | \hat{\theta}_{\rm MLE})\)
</span>
。 不幸的是，当样本量很小时，这种近似可能表现很差。例如，假设我们已经看到


<span class="katex">
  \(N=3\)
</span>
个连续&quot;反面&quot;。MLE是


<span class="katex">
  \(\hat{\theta}=0/3=0\)
</span>
，因为要尽可能用到所有观察到的数据。但是，使用这个估计，我们预测&quot;正面&quot;是不可能的。这被称为 <strong>零计数问题</strong> 或 <strong>稀疏数据问题</strong>，并且在从少量数据估计计数时经常发生。有人可能会认为，在“大数据”时代，这种担忧是无关紧要的，但请注意，一旦我们根据某些标准对数据进行区分 - 例如 _特定人员_从事_特定活动_的次数 - 样本量可以变的非常小。例如，当试图执行个性化推荐网页时, 会出现该问题。因此贝叶斯方法仍然有用，即使在大数据体系中也是如此（Jordan 2011）。</p>
<p>零计数问题类似于哲学中所谓<strong>黑天鹅悖论</strong>的问题。这是基于古老的西方观念，即所有天鹅都是白色的。在这种情况下，黑天鹅是一种不可能存在的隐喻。 （黑天鹅是17世纪欧洲探险家在澳大利亚发现的。）“黑天鹅悖论”这个词首先由著名的科学哲学家卡尔波普尔创造; 该术语也被用作最近一本畅销书（Taleb 2007）的标题。这个悖论被用来描述归纳问题，这是如何从过去的特定观察中得出关于未来的一般结论的问题。</p>
<p>现在让我们推导出一个简单的贝叶斯解决方案。我们将使用均匀先验，因此


<span class="katex">
  \(a = b = 1\)
</span>
。在这种情况下，插入后验均值, 得到<strong>拉普拉斯的继承规则</strong>:</p>



<span class="katex">
  \[
p(\tilde{x} = 1 | \mathcal{D}) = \dfrac{N_1 + 1}{N_1+N_0 + 2} \tag{3.30}
\]
</span>

<p>这种将经验计数加1，归一化, 然后插入的常见做法，被称为 <strong>加1平滑</strong>(add-one smoothing)。 （注意，在MAP参数中插入是不会有这种平滑效果，由于众数形如


<span class="katex">
  \(\hat{\theta} = \dfrac{a+N_1-1}{a+b+N-2}\)
</span>
, 如果


<span class="katex">
  \(a = b = 1\)
</span>
, 那么将变成MLE。）</p>
<h3 id="3341-预测多个未来试验的结果">3.3.4.1 预测多个未来试验的结果</h3>
<p>假设，我们现在感兴趣的是, 在


<span class="katex">
  \(M\)
</span>
次未来试验中, 预测出现&quot;正面&quot;的次数


<span class="katex">
  \(x\)
</span>
. 可由下式表示:</p>



<span class="katex">
  \[
\begin{aligned}
p(x | \mathcal{D},M) & = \int_0^1{{\rm Bin}(x | \theta,M){\rm Beta}(\theta | a, b) \ d \theta}  \\
\quad &  =\binom{M}{x} \dfrac{1}{B(a, b)} \int_0^1{ \theta^x (1-\theta)^{M-x} \theta^{a-1} (1-\theta)^{b-1} \ d \theta}  
\end{aligned}   \tag{3.31-32}
\]
</span>

<p>我们注意到


<span class="katex">
  \({\rm Beta}(a+x, M-x+b)\)
</span>
分布可以积分得到归一化常数。因此</p>



<span class="katex">
  \[
\int_0^1{ \theta^x (1-\theta)^{M-x} \theta^{a-1} (1-\theta)^{b-1} \ d \theta}=B(a+x, M-x+b) \tag{3.33}
\]
</span>

<p>于是，我们找到了后验预测的分布, 这就是被称作(复合的)


<span class="katex">
  \(\beta\)
</span>
**-二项分布**:</p>



<span class="katex">
  \[
{\rm Bb}(x | a,b,M) \overset{\Delta}{=} \binom{M}{x} \dfrac{B(a+x, M-x+b)}{B(a, b)} \tag{3.34}
\]
</span>

<p>该分布具有以下的均值和方差</p>



<span class="katex">
  \[
\mathbb{E}[x] = M \dfrac{a}{a+b}, \quad {\rm Var}[x]=\dfrac{M a b}{(a+b)^2} \dfrac{a+b+M}{a+b+1} \tag{3.35}
\]
</span>

<p>如果


<span class="katex">
  \(M=1\)
</span>
，于是


<span class="katex">
  \(x \in \{0,1\}\)
</span>
，我们看到，均值变成


<span class="katex">
  \(\mathbb{E}[x | \mathcal{D}] =p(x=1 | \mathcal{D})= \dfrac{a}{a+b}\)
</span>
，这与公式3.29是一致。</p>
<p>该过程如图3.7（a）所示。我们从


<span class="katex">
  \({\rm Beta}(2,2)\)
</span>
先验开始，并绘制了在看到


<span class="katex">
  \(N_1=3\)
</span>
个&quot;正面&quot;和


<span class="katex">
  \(N_0=17\)
</span>
个&quot;反面&quot;的后验预测密度。图3.7（b）绘制了使用MAP的插入近似。我们看到贝叶斯预测具有更长的尾部，更广泛地扩展其概率质量，因此不太容易出现过拟合和黑天鹅类的悖论。</p>
<p><a href="/notes/docs/mlapp/03generative_models_for_discrete_data/"><strong>返回本章目录</strong></a></p></article>

<hr>

<nav class="post-pagination">
  
  <a class="newer-posts" href="https://chaoskey.gitee.io/notes/docs/mlapp/03generative_models_for_discrete_data/0042/">
    下一页<br>3.4 狄利克雷-多项模型
  </a>
  
  
  
  <a class="older-posts" href="https://chaoskey.gitee.io/notes/docs/mlapp/03generative_models_for_discrete_data/0040/">
      上一页<br>3.2 贝叶斯概念学习
  </a>
  
</nav>

 

      <footer class="book-footer">
        
  <div class="flex justify-between">





  <div>
    <a class="flex align-center" href="https://gitee.com/chaoskey/notes/blob/master/content/docs/mlapp/03generative_models_for_discrete_data/0041.md#blob-comment" target="_blank" rel="noopener">
      <img src="/notes/svg/edit.svg" class="book-icon" alt="Comment" />
      <span>评论</span>
    </a>
  </div>
  
  
  <div>
    <a class="flex align-center" href="https://gitee.com/-/ide/project/chaoskey/notes/edit/master/-/content/docs/mlapp/03generative_models_for_discrete_data/0041.md" target="_blank" rel="noopener">
      <img src="/notes/svg/edit.svg" class="book-icon" alt="Edit" />
      <span>编辑本页</span>
    </a>
  </div>

</div>

 
        
  
  <div class="book-comments">

</div>
  
  
      </footer>
      
    </div>

    
    <aside class="book-toc">
      
  <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#331-拟然">3.3.1 拟然</a></li>
        <li><a href="#332-先验">3.3.2 先验</a></li>
        <li><a href="#333-后验">3.3.3 后验</a>
          <ul>
            <li><a href="#3331-后验均值和众数mode">3.3.3.1 后验均值和众数(mode)</a></li>
            <li><a href="#3332-后验方差">3.3.3.2 后验方差</a></li>
          </ul>
        </li>
        <li><a href="#334-后验预测分布">3.3.4 后验预测分布</a>
          <ul>
            <li><a href="#3341-过拟合和黑天鹅悖论">3.3.4.1 过拟合和黑天鹅悖论</a></li>
            <li><a href="#3341-预测多个未来试验的结果">3.3.4.1 预测多个未来试验的结果</a></li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</nav>

 
    </aside>
    
  </main>

  
</body>

</html>












